{
  "hash": "f28cdfcaf9bfcfbe03b74a6d304eb910",
  "result": {
    "markdown": "---\ntitle: \"A Complete Guide to Stepwise Regression in R\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-12-06\"\ncategories: [rtip, regression]\n---\n\n\n# Introduction\n\nStepwise regression is a powerful technique used to build predictive models by iteratively adding or removing variables based on statistical criteria. In R, this can be achieved using functions like `step()` or manually with forward and backward selection.\n\n# Example\n\n## Empty Model:\n\nLet's start with an empty model, an intercept only model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintercept_model <- lm(mpg ~ 1, data = mtcars)\nstep(intercept_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=115.94\nmpg ~ 1\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ 1, data = mtcars)\n\nCoefficients:\n(Intercept)  \n      20.09  \n```\n:::\n:::\n\n\nIn simple terms, we start with a model containing no predictors (`mpg ~ 1`) and iteratively add the most statistically significant variables until no improvement is observed. Since there are no predictors there is nothing to run through.\n\n## Forward Stepwise Regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize model\nforward_model <- lm(mpg ~ ., data = mtcars)\n\n# Forward stepwise regression\nforward_model <- step(forward_model, direction = \"forward\", scope = formula(~ .))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=70.9\nmpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb\n```\n:::\n:::\n\n\nIn simple terms, we start with a model containing all of the predictors (`mpg ~ .`) and iteratively add the most statistically significant variables until no improvement is observed.\n\n\n## Backward Stepwise Regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize a model with all predictors\nbackward_model <- lm(mpg ~ ., data = mtcars)\n\n# Backward stepwise regression\nbackward_model <- step(backward_model, direction = \"backward\", trace = 0)\n```\n:::\n\n\nHere, we begin with a model including all predictors and iteratively remove the least statistically significant variables until the model no longer improves.\n\n## Both-Direction Stepwise Regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize a model with all predictors\nboth_model <- lm(mpg ~ ., data = mtcars)\n\n# Both-direction stepwise regression\nboth_model <- step(both_model, direction = \"both\", trace = 0)\n```\n:::\n\n\nIn both-direction regression, the algorithm combines both forward and backward steps, optimizing the model by adding significant variables and removing insignificant ones.\n\n#### Visualizing Data and Model Fit:\n\nNow, let's visualize the data and model fit using base R plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatter plot of mpg vs. hp\nplot(mtcars$hp, mtcars$mpg, \n     main = \"Scatter Plot of mpg vs. hp\", \n     xlab = \"hp\", ylab = \"mpg\", pch = 20\n     )\nabline(lm(mpg ~ hp, data = mtcars), col = \"black\", lwd = 2)\npoints(sort(mtcars$hp), intercept_model$fitted.values, col = \"purple\", pch = 20)\npoints(sort(mtcars$hp), forward_model$fitted.values, col = \"red\", pch = 20)\npoints(sort(mtcars$hp), backward_model$fitted.values, col = \"blue\", pch = 20)\npoints(sort(mtcars$hp), both_model$fitted.values, col = \"green\", pch = 20)\n\nlegend(\n  \"topright\", \n  legend = c(\n    \"Intercept Only\", \n    \"Forward\", \n    \"Backward\", \n    \"Both-Direction\"\n    ),\n  col = c(\"red\", \"blue\", \"green\"), pch = 20\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThis plot displays the scatter plot of `mpg` against `hp` with fitted lines for each stepwise regression. The colors correspond to the models created earlier.\n\n#### Visualizing Residuals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residual plots for each model\npar(mfrow = c(2, 2))\n\n# Intercept Model\nplot(intercept_model$residuals, main = \"Intercept Residuals\", ylab = \"Residuals\")\n\n# Forward stepwise regression residuals\nplot(forward_model$residuals, main = \"Forward Residuals\", ylab = \"Residuals\")\n\n# Backward stepwise regression residuals\nplot(backward_model$residuals, main = \"Backward Residuals\", ylab = \"Residuals\")\n\n# Both-direction stepwise regression residuals\nplot(both_model$residuals, main = \"Both-Direction Residuals\", ylab = \"Residuals\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n```\n:::\n\n\nThese plots help assess how well the models fit the data by examining the residuals.\n\n# Conclusion\n\nStepwise regression is a valuable tool, but it's crucial to interpret results cautiously and be aware of potential pitfalls.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}