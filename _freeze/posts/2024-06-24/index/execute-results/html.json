{
  "hash": "0403dab438eb47a5ddbeafac5a9ec467",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An Introduction to healthyR.ai\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2024-06-24\"\ncategories: [code, rtip, healthyrai]\ntoc: TRUE\n---\n\n\n# Introduction\n\nThis post will introduction to the `healthyR.ai` package. The `healthyR.ai` package is a collection of functions that I have developed to help me analyze and visualize data. The package is designed to be easy to use and to provide a wide range of functionality for data analysis. The package is also meant to help and provide some easy boilerplate funcationality for machine learning.\n\nIt might be best to view this post in light mode to see the tables better.\n\n# Installation\n\nYou can install the released version of healthyR.ai from CRAN with:\n\n```r\ninstall.packages(\"healthyR.ai\")\n```\n\nAnd the development version from GitHub with:\n\n```r\n# install.packages(\"devtools\")\ndevtools::install_github(\"spsanderson/healthyR.ai\")\n```\n\n# Getting Started\n\n## The Goal\n\n---\n\nThe ultimate goal really is to make it easier to do data analysis and machine learning in R. The package is designed to be easy to use and to provide a wide range of functionality for data analysis. The package is also meant to help and provide some easy boilerplate functionality for machine learning. This package is in its early stages and will be updated frequently. \n\nIt also keeps with the same framework of all of the `healthyverse` packages in that it is meant for the user to be able to use the package without having to know a lot of R. Many rural hospitals do not have the resources to perform this sort of work, so I am working hard to build these types of things out for them for free.\n\nLet's go through some examples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(healthyR.ai)\nlibrary(tidyverse)\nlibrary(DT)\n```\n:::\n\n\nNow let's get a list of all the functions that are exposed in the package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Functions and their arguments for healthyR\n\npat <- c(\"%>%\",\":=\",\"as_label\",\"as_name\",\"enquo\",\"enquos\",\"expr\",\n         \"sym\",\"syms\",\"required_pkgs.step_hai_fourier\",\n         \"required_pkgs.step_hai_fourier_discrete\",\n         \"required_pkgs.step_hai_hyperbolic\",\n         \"required_pkgs.step_hai_scale_zero_one\",\n         \"required_pkgs.step_hai_scal_zscore\",\n         \"required_pkgs.step_hai_winsorized_move\",\n         \"required_pkgs.step_hai_winsorized_truncate\")\n\ntibble(fns = ls.str(\"package:healthyR.ai\")) |>\n  filter(!fns %in% pat) |>\n  mutate(params = purrr::map(fns, formalArgs)) |> \n  group_by(fns) |> \n  mutate(func_with_params = toString(params)) |>\n  mutate(\n    func_with_params = ifelse(\n      str_detect(\n        func_with_params, \"\\\\(\"), \n      paste0(fns, func_with_params), \n      paste0(fns, \"(\", func_with_params, \")\")\n    )) |>\n  select(fns, func_with_params) |>\n  mutate(fns = as.factor(fns)) |>\n  datatable(\n    #class = 'cell-boarder-stripe',\n    colnames = c(\"Function\", \"Full Call\"),\n    options = list(\n      autowidth = TRUE,\n      pageLength = 10\n    )\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-039d08720c7944584119\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-039d08720c7944584119\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\"],[\"color_blind\",\"get_juiced_data\",\"hai_auto_c50\",\"hai_auto_cubist\",\"hai_auto_earth\",\"hai_auto_glmnet\",\"hai_auto_knn\",\"hai_auto_ranger\",\"hai_auto_svm_poly\",\"hai_auto_svm_rbf\",\"hai_auto_wflw_metrics\",\"hai_auto_xgboost\",\"hai_c50_data_prepper\",\"hai_control_chart\",\"hai_cubist_data_prepper\",\"hai_data_impute\",\"hai_data_poly\",\"hai_data_scale\",\"hai_data_transform\",\"hai_data_trig\",\"hai_default_classification_metric_set\",\"hai_default_regression_metric_set\",\"hai_density_hist_plot\",\"hai_density_plot\",\"hai_density_qq_plot\",\"hai_distribution_comparison_tbl\",\"hai_earth_data_prepper\",\"hai_fourier_augment\",\"hai_fourier_discrete_augment\",\"hai_fourier_discrete_vec\",\"hai_fourier_vec\",\"hai_get_density_data_tbl\",\"hai_get_dist_data_tbl\",\"hai_glmnet_data_prepper\",\"hai_histogram_facet_plot\",\"hai_hyperbolic_augment\",\"hai_hyperbolic_vec\",\"hai_kmeans_automl\",\"hai_kmeans_automl_predict\",\"hai_kmeans_mapped_tbl\",\"hai_kmeans_obj\",\"hai_kmeans_scree_data_tbl\",\"hai_kmeans_scree_plot\",\"hai_kmeans_scree_plt\",\"hai_kmeans_tidy_tbl\",\"hai_kmeans_user_item_tbl\",\"hai_knn_data_prepper\",\"hai_kurtosis_vec\",\"hai_polynomial_augment\",\"hai_range_statistic\",\"hai_ranger_data_prepper\",\"hai_scale_color_colorblind\",\"hai_scale_fill_colorblind\",\"hai_scale_zero_one_augment\",\"hai_scale_zero_one_vec\",\"hai_scale_zscore_augment\",\"hai_scale_zscore_vec\",\"hai_skewed_features\",\"hai_skewness_vec\",\"hai_svm_poly_data_prepper\",\"hai_svm_rbf_data_prepper\",\"hai_umap_list\",\"hai_umap_plot\",\"hai_winsorized_move_augment\",\"hai_winsorized_move_vec\",\"hai_winsorized_truncate_augment\",\"hai_winsorized_truncate_vec\",\"hai_xgboost_data_prepper\",\"kmeans_mapped_tbl\",\"kmeans_obj\",\"kmeans_scree_data_tbl\",\"kmeans_scree_plt\",\"kmeans_tidy_tbl\",\"kmeans_user_item_tbl\",\"pca_your_recipe\",\"required_pkgs.step_hai_scale_zscore\",\"step_hai_fourier\",\"step_hai_fourier_discrete\",\"step_hai_hyperbolic\",\"step_hai_scale_zero_one\",\"step_hai_scale_zscore\",\"step_hai_winsorized_move\",\"step_hai_winsorized_truncate\",\"umap_list\",\"umap_plt\"],[\"color_blind(NULL)\",\"get_juiced_data(.recipe_object)\",\"hai_auto_c50c(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_cubistc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\")\",\"hai_auto_earthc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_glmnetc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_knnc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_rangerc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_svm_polyc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_svm_rbfc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_auto_wflw_metrics(.data)\",\"hai_auto_xgboostc(\\\".data\\\", \\\".rec_obj\\\", \\\".splits_obj\\\", \\\".rsamp_obj\\\", \\\".tune\\\", \\\".grid_size\\\", \\\".num_cores\\\", \\\".best_metric\\\", \\\".model_type\\\")\",\"hai_c50_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_control_chartc(\\\".data\\\", \\\".value_col\\\", \\\".x_col\\\", \\\".center_line\\\", \\\".std_dev\\\", \\\".plt_title\\\", \\\".plt_catpion\\\", \\\".plt_font_size\\\", \\\".print_plot\\\")\",\"hai_cubist_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_data_imputec(\\\".recipe_object\\\", \\\"...\\\", \\\".seed_value\\\", \\\".type_of_imputation\\\", \\\".number_of_trees\\\", \\\".neighbors\\\", \\\".mean_trim\\\", \\\".roll_statistic\\\", \\\".roll_window\\\")\",\"hai_data_polyc(\\\".recipe_object\\\", \\\"...\\\", \\\".p_degree\\\")\",\"hai_data_scalec(\\\".recipe_object\\\", \\\"...\\\", \\\".type_of_scale\\\", \\\".range_min\\\", \\\".range_max\\\", \\\".scale_factor\\\")\",\"hai_data_transformc(\\\".recipe_object\\\", \\\"...\\\", \\\".type_of_scale\\\", \\\".bc_limits\\\", \\\".bc_num_unique\\\", \\\".bs_deg_free\\\", \\\".bs_degree\\\", \\\".log_base\\\", \\\".log_offset\\\", \\\".logit_offset\\\", \\\".ns_deg_free\\\", \\\".rel_shift\\\", \\\".rel_reverse\\\", \\\".rel_smooth\\\", \\\".yj_limits\\\", \\\".yj_num_unique\\\")\",\"hai_data_trigc(\\\".recipe_object\\\", \\\"...\\\", \\\".type_of_scale\\\", \\\".inverse\\\")\",\"hai_default_classification_metric_set(NULL)\",\"hai_default_regression_metric_set(NULL)\",\"hai_density_hist_plotc(\\\".data\\\", \\\".dist_name_col\\\", \\\".value_col\\\", \\\".alpha\\\", \\\".interactive\\\")\",\"hai_density_plotc(\\\".data\\\", \\\".dist_name_col\\\", \\\".x_col\\\", \\\".y_col\\\", \\\".size\\\", \\\".alpha\\\", \\\".interactive\\\")\",\"hai_density_qq_plotc(\\\".data\\\", \\\".dist_name_col\\\", \\\".x_col\\\", \\\".y_col\\\", \\\".size\\\", \\\".alpha\\\", \\\".interactive\\\")\",\"hai_distribution_comparison_tblc(\\\".x\\\", \\\".distributions\\\", \\\".normalize\\\")\",\"hai_earth_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_fourier_augmentc(\\\".data\\\", \\\".value\\\", \\\".period\\\", \\\".order\\\", \\\".names\\\", \\\".scale_type\\\")\",\"hai_fourier_discrete_augmentc(\\\".data\\\", \\\".value\\\", \\\".period\\\", \\\".order\\\", \\\".names\\\", \\\".scale_type\\\")\",\"hai_fourier_discrete_vecc(\\\".x\\\", \\\".period\\\", \\\".order\\\", \\\".scale_type\\\")\",\"hai_fourier_vecc(\\\".x\\\", \\\".period\\\", \\\".order\\\", \\\".scale_type\\\")\",\"hai_get_density_data_tblc(\\\".data\\\", \\\".unnest\\\", \\\".group_data\\\")\",\"hai_get_dist_data_tblc(\\\".data\\\", \\\".unnest\\\", \\\".group_data\\\")\",\"hai_glmnet_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_histogram_facet_plotc(\\\".data\\\", \\\".bins\\\", \\\".scale_data\\\", \\\".ncol\\\", \\\".fct_reorder\\\", \\\".fct_rev\\\", \\\".fill\\\", \\\".color\\\", \\\".scale\\\", \\\".interactive\\\")\",\"hai_hyperbolic_augmentc(\\\".data\\\", \\\".value\\\", \\\".names\\\", \\\".scale_type\\\")\",\"hai_hyperbolic_vecc(\\\".x\\\", \\\".scale_type\\\")\",\"hai_kmeans_automlc(\\\".data\\\", \\\".split_ratio\\\", \\\".seed\\\", \\\".centers\\\", \\\".standardize\\\", \\\".print_model_summary\\\", \\\".predictors\\\", \\\".categorical_encoding\\\", \\\".initialization_mode\\\", \\\".max_iterations\\\")\",\"hai_kmeans_automl_predict(.input)\",\"hai_kmeans_mapped_tblc(\\\".data\\\", \\\".centers\\\")\",\"hai_kmeans_objc(\\\".data\\\", \\\".centers\\\")\",\"hai_kmeans_scree_data_tbl(.data)\",\"hai_kmeans_scree_plot(.data)\",\"hai_kmeans_scree_plt(.data)\",\"hai_kmeans_tidy_tblc(\\\".kmeans_obj\\\", \\\".data\\\", \\\".tidy_type\\\")\",\"hai_kmeans_user_item_tblc(\\\".data\\\", \\\".row_input\\\", \\\".col_input\\\", \\\".record_input\\\")\",\"hai_knn_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_kurtosis_vec(.x)\",\"hai_polynomial_augmentc(\\\".data\\\", \\\".formula\\\", \\\".pred_col\\\", \\\".degree\\\", \\\".new_col_prefix\\\")\",\"hai_range_statistic(.x)\",\"hai_ranger_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_scale_color_colorblindc(\\\"...\\\", \\\"theme\\\")\",\"hai_scale_fill_colorblindc(\\\"...\\\", \\\"theme\\\")\",\"hai_scale_zero_one_augmentc(\\\".data\\\", \\\".value\\\", \\\".names\\\")\",\"hai_scale_zero_one_vec(.x)\",\"hai_scale_zscore_augmentc(\\\".data\\\", \\\".value\\\", \\\".names\\\")\",\"hai_scale_zscore_vec(.x)\",\"hai_skewed_featuresc(\\\".data\\\", \\\".threshold\\\", \\\".drop_keys\\\")\",\"hai_skewness_vec(.x)\",\"hai_svm_poly_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_svm_rbf_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"hai_umap_listc(\\\".data\\\", \\\".kmeans_map_tbl\\\", \\\".k_cluster\\\")\",\"hai_umap_plotc(\\\".data\\\", \\\".point_size\\\", \\\".label\\\")\",\"hai_winsorized_move_augmentc(\\\".data\\\", \\\".value\\\", \\\".multiple\\\", \\\".names\\\")\",\"hai_winsorized_move_vecc(\\\".x\\\", \\\".multiple\\\")\",\"hai_winsorized_truncate_augmentc(\\\".data\\\", \\\".value\\\", \\\".fraction\\\", \\\".names\\\")\",\"hai_winsorized_truncate_vecc(\\\".x\\\", \\\".fraction\\\")\",\"hai_xgboost_data_prepperc(\\\".data\\\", \\\".recipe_formula\\\")\",\"kmeans_mapped_tblc(\\\".data\\\", \\\".centers\\\")\",\"kmeans_objc(\\\".data\\\", \\\".centers\\\")\",\"kmeans_scree_data_tbl(.data)\",\"kmeans_scree_plt(.data)\",\"kmeans_tidy_tblc(\\\".kmeans_obj\\\", \\\".data\\\", \\\".tidy_type\\\")\",\"kmeans_user_item_tblc(\\\".data\\\", \\\".row_input\\\", \\\".col_input\\\", \\\".record_input\\\")\",\"pca_your_recipec(\\\".recipe_object\\\", \\\".data\\\", \\\".threshold\\\", \\\".top_n\\\")\",\"required_pkgs.step_hai_scale_zscorec(\\\"x\\\", \\\"...\\\")\",\"step_hai_fourierc(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"scale_type\\\", \\\"period\\\", \\\"order\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_fourier_discretec(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"scale_type\\\", \\\"period\\\", \\\"order\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_hyperbolicc(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"scale_type\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_scale_zero_onec(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_scale_zscorec(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_winsorized_movec(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"multiple\\\", \\\"skip\\\", \\\"id\\\")\",\"step_hai_winsorized_truncatec(\\\"recipe\\\", \\\"...\\\", \\\"role\\\", \\\"trained\\\", \\\"columns\\\", \\\"fraction\\\", \\\"skip\\\", \\\"id\\\")\",\"umap_listc(\\\".data\\\", \\\".kmeans_map_tbl\\\", \\\".k_cluster\\\")\",\"umap_pltc(\\\".data\\\", \\\".point_size\\\", \\\".label\\\")\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Function<\\/th>\\n      <th>Full Call<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"autowidth\":true,\"pageLength\":10,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"fns\",\"targets\":1},{\"name\":\"func_with_params\",\"targets\":2}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n# Examples\n\nLet's start off going through an example of using the function, `pca_your_repipe`. First, the syntax.\n\n## Example - PCA a recipe\n\n### Syntax\n\n```r\npca_your_recipe(.recipe_object, .data, .threshold = 0.75, .top_n = 5)\n```\n\n### Arguments\n\n*   `.recipe_object` - \n*   `.data` - The full data set that is used in the original recipe object passed into .recipe_object in order to obtain the baked data of the transform.\n*   `.threshold` - A number between 0 and 1. A fraction of the total variance that should be covered by the components.\n*   `.top_n` - How many variables loadings should be returned per PC\n\n### Value\n\nA list object with several components.\n\n### Details\n\nThis is a simple wrapper around some recipes functions to perform a PCA on a given recipe. This function will output a list and return it invisible. All of the components of the analysis will be returned in a list as their own object that can be selected individually. A scree plot is also included. The items that get returned are:\n\n-   pca_transform - This is the pca recipe.\n-   variable_loadings\n-   variable_variance\n-   pca_estimates\n-   pca_juiced_estimates\n-   pca_baked_data\n-   pca_variance_df\n-   pca_rotattion_df\n-   pca_variance_scree_plt\n-   pca_loadings_plt\n-   pca_loadings_plotly\n-   pca_top_n_loadings_plt\n-   pca_top_n_plotly\n\n### Working Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(recipes)\n\nsplits <- initial_split(mtcars, prop = 0.8)\n\nrec_obj <- recipe(mpg ~ ., data = training(splits)) |>\n  step_normalize(all_predictors())\n\npca_output <- pca_your_recipe(\n  .recipe_object = rec_obj, \n  .data = mtcars, \n  .threshold = 0.75, \n  .top_n = 5\n  )\n```\n:::\n\n\nNow let's check the output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca_output\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$pca_transform\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:    1\npredictor: 10\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Centering and scaling for: all_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Centering for: recipes::all_numeric()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Scaling for: recipes::all_numeric()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Sparse, unbalanced variable filter on: recipes::all_numeric()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• PCA extraction with: recipes::all_numeric_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$variable_loadings\n# A tibble: 100 × 4\n   terms  value component id       \n   <chr>  <dbl> <chr>     <chr>    \n 1 cyl   -0.394 PC1       pca_RSbN6\n 2 disp  -0.389 PC1       pca_RSbN6\n 3 hp    -0.356 PC1       pca_RSbN6\n 4 drat   0.321 PC1       pca_RSbN6\n 5 wt    -0.358 PC1       pca_RSbN6\n 6 qsec   0.248 PC1       pca_RSbN6\n 7 vs     0.319 PC1       pca_RSbN6\n 8 am     0.248 PC1       pca_RSbN6\n 9 gear   0.238 PC1       pca_RSbN6\n10 carb  -0.232 PC1       pca_RSbN6\n# ℹ 90 more rows\n\n$variable_variance\n# A tibble: 40 × 4\n   terms     value component id       \n   <chr>     <dbl>     <int> <chr>    \n 1 variance 6.09           1 pca_RSbN6\n 2 variance 2.42           2 pca_RSbN6\n 3 variance 0.619          3 pca_RSbN6\n 4 variance 0.231          4 pca_RSbN6\n 5 variance 0.215          5 pca_RSbN6\n 6 variance 0.171          6 pca_RSbN6\n 7 variance 0.112          7 pca_RSbN6\n 8 variance 0.0848         8 pca_RSbN6\n 9 variance 0.0409         9 pca_RSbN6\n10 variance 0.0219        10 pca_RSbN6\n# ℹ 30 more rows\n\n$pca_estimates\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:    1\npredictor: 10\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Training information \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTraining data contained 25 data points and no incomplete rows.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Centering and scaling for: cyl, disp, hp, drat, wt, qsec, ... | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Centering for: cyl, disp, hp, drat, wt, qsec, vs, am, gear, ... | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Scaling for: cyl, disp, hp, drat, wt, qsec, vs, am, gear, ... | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Sparse, unbalanced variable filter removed: <none> | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• PCA extraction with: cyl, disp, hp, drat, wt, qsec, vs, am, ... | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$pca_juiced_estimates\n# A tibble: 25 × 3\n       mpg    PC1      PC2\n     <dbl>  <dbl>    <dbl>\n 1 -1.67   -3.54  -0.529  \n 2  0.0945  0.633  2.03   \n 3  0.394   2.31  -1.60   \n 4  0.178   1.88  -1.88   \n 5  1.99    3.29   0.00164\n 6  1.66    3.79   0.988  \n 7 -0.670  -2.14  -0.503  \n 8 -0.953  -3.45  -0.248  \n 9  2.24    3.59   0.0209 \n10  0.161   2.47   0.534  \n# ℹ 15 more rows\n\n$pca_baked_data\n# A tibble: 32 × 3\n       mpg    PC1    PC2\n     <dbl>  <dbl>  <dbl>\n 1  0.0945  0.633  2.03 \n 2  0.0945  0.613  1.87 \n 3  0.394   2.76   0.137\n 4  0.161   0.228 -2.17 \n 5 -0.288  -2.01  -0.623\n 6 -0.388   0.191 -2.55 \n 7 -1.02   -2.82   0.438\n 8  0.660   1.91  -1.13 \n 9  0.394   2.31  -1.60 \n10 -0.205   0.622  0.125\n# ℹ 22 more rows\n\n$pca_variance_df\n# A tibble: 10 × 6\n   PC    var_explained var_pct_txt cum_var_pct cum_var_pct_txt ou_threshold\n   <chr>         <dbl> <chr>             <dbl> <chr>           <fct>       \n 1 PC1         0.609   60.86%            0.609 60.86%          Under       \n 2 PC2         0.242   24.19%            0.850 85.05%          Over        \n 3 PC3         0.0619  6.19%             0.912 91.24%          Over        \n 4 PC4         0.0231  2.31%             0.935 93.55%          Over        \n 5 PC5         0.0215  2.15%             0.957 95.70%          Over        \n 6 PC6         0.0171  1.71%             0.974 97.41%          Over        \n 7 PC7         0.0112  1.12%             0.985 98.52%          Over        \n 8 PC8         0.00848 0.85%             0.994 99.37%          Over        \n 9 PC9         0.00409 0.41%             0.998 99.78%          Over        \n10 PC10        0.00219 0.22%             1     100.00%         Over        \n\n$pca_rotation_df\n# A tibble: 10 × 10\n      PC1     PC2     PC3     PC4      PC5     PC6     PC7     PC8     PC9\n    <dbl>   <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 -0.394  0.0328 -0.146   0.0804 -0.162    0.0655 -0.223  -0.0200 -0.728 \n 2 -0.389 -0.0623  0.0134 -0.0763  0.200   -0.383   0.447   0.0126 -0.369 \n 3 -0.356  0.213   0.240   0.342  -0.195   -0.145   0.270   0.614   0.282 \n 4  0.321  0.295   0.0556  0.336   0.768   -0.125  -0.0333  0.127  -0.204 \n 5 -0.358 -0.124   0.391  -0.367   0.305   -0.347  -0.105  -0.338   0.262 \n 6  0.248 -0.432   0.425  -0.317   0.00567 -0.0377 -0.272   0.568  -0.259 \n 7  0.319 -0.255   0.421   0.505  -0.328   -0.313   0.156  -0.373  -0.163 \n 8  0.248  0.443  -0.217  -0.241  -0.294   -0.693  -0.253   0.0794 -0.0246\n 9  0.238  0.449   0.346  -0.431  -0.125    0.278   0.509  -0.0781 -0.222 \n10 -0.232  0.445   0.490   0.151  -0.0541   0.189  -0.494  -0.133  -0.0201\n# ℹ 1 more variable: PC10 <dbl>\n\n$pca_variance_scree_plt\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$pca_loadings_plt\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$pca_loadings_plotly\n\n$pca_top_n_loadings_plt\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$pca_top_n_plotly\n```\n\n\n:::\n:::\n\n\nPretty easy as you can see.\n\n## Example - Histogram Facet Plot\n\n### Syntax\n\n```r\nhai_histogram_facet_plot(\n  .data,\n  .bins = 10,\n  .scale_data = FALSE,\n  .ncol = 5,\n  .fct_reorder = FALSE,\n  .fct_rev = FALSE,\n  .fill = \"steelblue\",\n  .color = \"white\",\n  .scale = \"free\",\n  .interactive = FALSE\n)\n```\n\n### Arguments\n\n*   `.data` - The data you want to pass to the function.\n*   `.bins` - The number of bins for the histograms.\n*   `.scale_data` - This is a boolean set to FALSE. TRUE will use hai_scale_zero_one_vec() to [0, 1] scale the data.\n*   `.ncol` - The number of columns for the facet_warp argument.\n*   `.fct_reorder` - Should the factor column be reordered? TRUE/FALSE, default of FALSE\n*   `.fct_rev` - Should the factor column be reversed? TRUE/FALSE, default of FALSE\n*   `.fill` - Default is steelblue\n*   `.color` - Default is 'white'\n*   `.scale` - Default is 'free'\n*   `.interactive` - Default is FALSE, TRUE will produce a plotly plot.\n\n### Working Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhai_histogram_facet_plot(mtcars, .interactive = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhai_histogram_facet_plot(mtcars, .interactive = FALSE, .scale_data = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n## Example - Boilerplacte Funcationality\n\nNow we are going to go over some simple boilerplate funcationality. I call it boilerplate because you don't have to change anything if you dont want to. For the boilerplate function there is a corresponding data preprocessor that will get the data into the shape it needs to be in for the algorithm. Let's take a look.\n\n### Working Example\n\nFirst lets look at the data, then we will look at it after the preprocessor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_obj <- hai_earth_data_prepper(iris, Species ~ .)\n\nrec_obj\n```\n:::\n\n\nNow to run it through the boilerplate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauto_earth <- hai_auto_earth(\n  .data = iris,\n  .rec_obj = rec_obj,\n  .best_metric = \"f_meas\",\n  .model_type = \"classification\"\n)\n```\n:::\n\n\nNow let's inspect the output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(auto_earth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"recipe_info\" \"model_info\"  \"tuned_info\" \n```\n\n\n:::\n:::\n\n\n### Recipe Information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauto_earth[[\"recipe_info\"]]\n```\n:::\n\n\n### Model Information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauto_earth[[\"model_info\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$model_spec\nMARS Model Specification (classification)\n\nMain Arguments:\n  num_terms = tune::tune()\n  prod_degree = tune::tune()\n  prune_method = none\n\nComputational engine: earth \n\n\n$wflw\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mars()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_string2factor()\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nMARS Model Specification (classification)\n\nMain Arguments:\n  num_terms = tune::tune()\n  prod_degree = tune::tune()\n  prune_method = none\n\nComputational engine: earth \n\n\n$fitted_wflw\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mars()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_string2factor()\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nGLM (family binomial, link logit):\n           nulldev  df       dev  df   devratio     AIC iters converged\nsetosa     144.779 111   52.6908 110     0.6360   56.69    22         1\nversicolor 137.505 111  125.5536 110     0.0869  129.60     4         1\nvirginica  144.779 111   15.1575 110     0.8950   19.16     9         1\n\nEarth selected 2 of 15 terms, and 1 of 4 predictors (pmethod=\"none\") (nprune=2)\nTermination condition: Reached nk 21\nImportance: Petal.Length-unused, Sepal.Length-unused, Sepal.Width-unused, ...\nNumber of terms at each degree of interaction: 1 1 (additive model)\n\nEarth\n                  GCV       RSS       GRSq        RSq\nsetosa     0.15145196 16.066078 0.34455933 0.36796602\nversicolor 0.20252995 21.484449 0.05906052 0.09266277\nvirginica  0.04535734  4.811523 0.80370644 0.81071635\nAll        0.36072282 38.265605 0.46747354 0.48649080\n\n$was_tuned\n[1] \"tuned\"\n```\n\n\n:::\n:::\n\n\n### Tuned Information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauto_earth[[\"tuned_info\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$tuning_grid\n# A tibble: 7 × 2\n  num_terms prod_degree\n      <int>       <int>\n1         3           2\n2         4           1\n3         5           2\n4         3           1\n5         4           2\n6         2           2\n7         2           1\n\n$cv_obj\n# Monte Carlo cross-validation (0.75/0.25) with 25 resamples  \n# A tibble: 25 × 2\n   splits          id        \n   <list>          <chr>     \n 1 <split [84/28]> Resample01\n 2 <split [84/28]> Resample02\n 3 <split [84/28]> Resample03\n 4 <split [84/28]> Resample04\n 5 <split [84/28]> Resample05\n 6 <split [84/28]> Resample06\n 7 <split [84/28]> Resample07\n 8 <split [84/28]> Resample08\n 9 <split [84/28]> Resample09\n10 <split [84/28]> Resample10\n# ℹ 15 more rows\n\n$tuned_results\n# Tuning results\n# Monte Carlo cross-validation (0.75/0.25) with 25 resamples  \n# A tibble: 25 × 4\n   splits          id         .metrics          .notes          \n   <list>          <chr>      <list>            <list>          \n 1 <split [84/28]> Resample01 <tibble [77 × 6]> <tibble [5 × 3]>\n 2 <split [84/28]> Resample02 <tibble [77 × 6]> <tibble [5 × 3]>\n 3 <split [84/28]> Resample03 <tibble [77 × 6]> <tibble [5 × 3]>\n 4 <split [84/28]> Resample04 <tibble [77 × 6]> <tibble [5 × 3]>\n 5 <split [84/28]> Resample05 <tibble [77 × 6]> <tibble [5 × 3]>\n 6 <split [84/28]> Resample06 <tibble [77 × 6]> <tibble [5 × 3]>\n 7 <split [84/28]> Resample07 <tibble [77 × 6]> <tibble [5 × 3]>\n 8 <split [84/28]> Resample08 <tibble [77 × 6]> <tibble [5 × 3]>\n 9 <split [84/28]> Resample09 <tibble [77 × 6]> <tibble [5 × 3]>\n10 <split [84/28]> Resample10 <tibble [77 × 6]> <tibble [5 × 3]>\n# ℹ 15 more rows\n\nThere were issues with some computations:\n\n  - Warning(s) x5: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x6: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x1: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x1: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x2: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x1: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x5: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x4: While computing multiclass `precision()`, some levels had no pred...\n  - Warning(s) x48: glm.fit: algorithm did not converge, glm.fit: fitted probabilitie...\n  - Warning(s) x2: glm.fit: algorithm did not converge, glm.fit: fitted probabilitie...\n  - Warning(s) x49: glm.fit: fitted probabilities numerically 0 or 1 occurred, glm.fi...\n  - Warning(s) x1: glm.fit: fitted probabilities numerically 0 or 1 occurred, glm.fi...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n$grid_size\n[1] 10\n\n$best_metric\n[1] \"f_meas\"\n\n$best_result_set\n# A tibble: 1 × 8\n  num_terms prod_degree .metric .estimator  mean     n std_err .config          \n      <int>       <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>            \n1         2           1 f_meas  macro      0.124    25  0.0154 Preprocessor1_Mo…\n\n$tuning_grid_plot\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n$plotly_grid_plot\n```\n\n\n:::\n:::\n\n\n# Metric Sets\n\nWith this package there comes some metric set's that can be computed using the `yardstick` package. These are the metric sets that are available:\n\n## Classification\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhai_default_classification_metric_set()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA metric set, consisting of:\n- `sensitivity()`, a class metric  | direction: maximize\n- `specificity()`, a class metric  | direction: maximize\n- `recall()`, a class metric       | direction: maximize\n- `precision()`, a class metric    | direction: maximize\n- `mcc()`, a class metric          | direction: maximize\n- `accuracy()`, a class metric     | direction: maximize\n- `f_meas()`, a class metric       | direction: maximize\n- `kap()`, a class metric          | direction: maximize\n- `ppv()`, a class metric          | direction: maximize\n- `npv()`, a class metric          | direction: maximize\n- `bal_accuracy()`, a class metric | direction: maximize\n```\n\n\n:::\n:::\n\n\n## Regression\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhai_default_regression_metric_set()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA metric set, consisting of:\n- `mae()`, a numeric metric   | direction: minimize\n- `mape()`, a numeric metric  | direction: minimize\n- `mase()`, a numeric metric  | direction: minimize\n- `smape()`, a numeric metric | direction: minimize\n- `rmse()`, a numeric metric  | direction: minimize\n- `rsq()`, a numeric metric   | direction: maximize\n```\n\n\n:::\n:::\n\n\nHere is a list of the items currently on it as of writing this article:\n\n\n1.    **Plotting Functions** - Functions for plotting.\n2.    **Clustering Functions** - Functions for clustering and analysis.\n3.    **Boiler Plate Functions** - Functions for automatic recipes, workflows, and tuned models.\n4.    **Dimensionality Reduction** - Functions for dimension reduction.\n5.    **Data Wrangling** - Functions for data wrangling.\n6.    **Data Preprocessors** - Functions for data preprocessing.\n7.    **Recipe Steps** - Functions to add recipe steps.\n8.    **Table Functions** - Functions that return tibbles.\n9.    **Vectorized Functions** - Vector functions.\n10.   **Augmenting Functions** - Functions for data augmentation.\n11.   **Miscellaneous Functions** - Miscellaneous utility functions.\n12.   **Metric Sets** - Metric sets for evaluation.\n\nFor more detailed information, you can visit the [healthyR.ai function reference page](https://www.spsanderson.com/healthyR.ai/reference/).\n\n# Conclusion\n\nI hope this helped a bit with understanding the `healthyR.ai` package. It is a very powerful package that can help you with a lot of different tasks. I will be writing more about this package in the future. If you have any questions or comments, please feel free to reach out to me at any of these:\n\nPeople can get in touch with you through the following social profiles:\n\n- **LinkedIn**: [linkedin.com/in/spsanderson](https://www.linkedin.com/in/spsanderson)\n- **Mastodon**: [mstdn.social/@stevensanderson](https://mstdn.social/@stevensanderson)\n- **Telegram**: [t.me/steveondata](https://t.me/steveondata)\n\n---\n\nHappy coding!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}