{
  "hash": "0bbe0ab38ba850fa238e60165d7ad0bb",
  "result": {
    "markdown": "---\ntitle: \"Unveiling Power Regression: A Step-by-Step Guide in R\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-11-27\"\ncategories: [rtip, regression]\n---\n\n\n# Introduction\n\nIn the realm of statistics, power regression stands out as a versatile tool for exploring the relationship between two variables, where one variable is the power of the other. This type of regression is particularly useful when there's an inherent nonlinear relationship between the variables, often characterized by an exponential or inverse relationship.\n\nPower regression takes the form of y = ax^b, where:\n\n*   `y`: The response variable, the quantity we're trying to predict\n\n*   `x`: The predictor variable, the quantity we're using to make predictions\n\n*   `a`: The intercept, the value of y when x = 1\n\n*   `b`: The power coefficient, which determines the rate at which y changes as x increases or decreases\n\n# Steps\n\n## Step 1: Gathering the Data\n\nTo embark on our power regression journey, we'll need some data to work with. Let's simulate a dataset that exhibits an exponential relationship between two variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate data\nx <- seq(1, 100, 1)\ny <- 2 * x^3 + rnorm(100)\n```\n:::\n\n\n## Step 2: Visualizing the Data\n\nBefore diving into the regression analysis, it's crucial to visualize the data to gain a deeper understanding of the underlying relationship between the variables. A scatterplot can effectively reveal any patterns or trends in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create scatterplot\nplot(x, y)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Step 3: Transforming the Data\n\nSince power regression assumes a nonlinear relationship between the variables, we need to transform the data to fit the model's structure. This involves taking the logarithm of both sides of the power regression equation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transform data\nlog_y <- log(y)\nlog_x <- log(x)\n```\n:::\n\n\n## Step 4: Fitting the Power Regression Model\n\nNow that the data is suitably transformed, we can proceed with fitting the power regression model using the `lm()` function in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit power regression model\nmodel <- lm(log_y ~ log_x)\n```\n:::\n\n\n## Step 5: Examining the Model Results\n\nThe `summary()` function provides valuable insights into the model's performance, including the estimated regression coefficients, their standard errors, and the p-values associated with each coefficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summarize model results\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log_y ~ log_x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.10472 -0.01800  0.00221  0.01433  0.61505 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.812631   0.027647   29.39   <2e-16 ***\nlog_x       2.969125   0.007367  403.03   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06803 on 98 degrees of freedom\nMultiple R-squared:  0.9994,\tAdjusted R-squared:  0.9994 \nF-statistic: 1.624e+05 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## Step 6: Visualizing the Fitted Model\n\nVisualizing the fitted model allows us to evaluate how well the model captures the underlying relationship between the variables. We can add the fitted model to the scatterplot using the `predict()` function (don't forget to exponentiate!):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict fitted values\nfitted_values <- predict(model, newdata = data.frame(x = x),\n                        interval = \"prediction\",\n                        level = 0.95)\n\n# Add fitted model to scatterplot\nplot(x, y)\nlines(x, exp(fitted_values[, 1]), col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Step 7: Calculating Prediction Intervals\n\nPrediction intervals provide a range of plausible values for the response variable at a given level of confidence. We calculated the prediction intervals using the `predict()` function above:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add fitted model to scatterplot\nplot(x, y)\nlines(x, exp(fitted_values[, 1]), col = \"red\")\n\n# Add prediction intervals to scatterplot\nlines(x, exp(fitted_values[, 2]), col = \"blue\", lty = 2)\nlines(x, exp(fitted_values[, 3]), col = \"blue\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n# Conclusion\n\nPower regression serves as a powerful tool for modeling nonlinear relationships between variables. By transforming the data, fitting the model, and visualizing the results, we can gain valuable insights into the underlying patterns and make informed predictions about the response variable.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}